{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Frontiers for Single/Multiple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to set up the notebook.\n",
    "\n",
    "# These lines import the Numpy, Pandas, Seaborn, Matplotlib modules.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Importing plotting libraries and styles\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# For Pandas to ignore FutureWarning displays\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The cell given below sets up MATLAB for the notebook\n",
    "Source: https://sehyoun.com/blog/20180904_using-matlab-with-jupyter-notebook.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matlab.engine\n",
    "import io\n",
    "import scipy.io\n",
    "from IPython.core.magic import register_cell_magic\n",
    "ip = get_ipython()\n",
    "\n",
    "out = io.StringIO()\n",
    "err = io.StringIO()\n",
    "\n",
    "# Setup matlab cell magic #\n",
    "@register_cell_magic\n",
    "def matlab_magic(line,cell):\n",
    "    out.truncate(0)\n",
    "    out.seek(0)\n",
    "    err.truncate(0)\n",
    "    err.truncate(0)\n",
    "    raw = '''{line}.eval(\"\"\"{cell}\"\"\", nargout=0, stdout=out, stderr=err)'''\n",
    "    ip.run_cell(raw.format(line=line, cell=cell))\n",
    "    print(out.getvalue())\n",
    "    print(err.getvalue())\n",
    "    \n",
    "# Starting a MATLAB engine called eng\n",
    "eng = matlab.engine.start_matlab()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Change this to the file path on your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds the MMB.m as well as MMBOPT1.m and MMBOPT2.m folders to the MATLAB engine path\"\n",
    "eng.addpath(r'/Users/Desktop/monetaryPolicy/mmb-gui-mlab-2.3.2', nargout=0)\n",
    "eng.addpath(r'/Users/Desktop/monetaryPolicy/mmb-gui-mlab-2.3.2/MMB_OPTIONS', nargout=0)\n",
    "eng.addpath(r'/Users/Desktop/monetaryPolicy/scripts', nargout=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important:\n",
    "The code below sets the coefficients and other data for the PID rule to work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the coefficients table here:\n",
    "\n",
    "https://rishab231.github.io/img/coefficients.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This sets the coefficients of the monetary policy rule, there are 33 coefficients and len(coefficients) = 33\n",
    "coefficients = [0, 0, 0, 0, 1.5/4, 1.5/4, 1.5/4, 1.5/4, \n",
    "                0, 0, 0, 0, 0, 0.5, 0, 0, \n",
    "                0, 0, 0, 0, 0, 0, 0, 0, \n",
    "                0, 0, 0, 0, 0, 0, 0, 1, 0.25]\n",
    "\n",
    "# Number of the model you want to chooose, please exclude 69-79, 19-22, 27, 59, 65, 68, 81, 97, 98\n",
    "modelNum = 1\n",
    "\n",
    "scipy.io.savemat('variables.mat', dict(coefficients=coefficients, modelNumber = modelNum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test run for MMB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng.MMB(nargout = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to get model name as well as the unconditional variances\n",
    "\n",
    "def getModelName():\n",
    "    irf_4 = pd.read_excel(\"../mmb-gui-mlab-2.3.2/OUTPUT/results.xls\", sheetname = \"IRF Mon. Pol. Shock      \")\n",
    "    irf_4 = irf_4.T\n",
    "    irf_headers = irf_4.iloc[0] # grab the first row for the header\n",
    "    irf_4 = irf_4[1:] # take the data less the header row\n",
    "    irf_4_stripped_headers = [myHeader.strip() for myHeader in np.array(irf_headers)] # removing trailing whitespaces\n",
    "    irf_4.columns = irf_4_stripped_headers\n",
    "    modelName = irf_4.columns.values[1]\n",
    "    return modelName\n",
    "\n",
    "def unconditionalVariances():\n",
    "    var4 = pd.read_csv(\"../mmb-gui-mlab-2.3.2/OUTPUT/variances.csv\", names=[\"interest\", \"inflation\", \"outputgap\", \"output\"])\n",
    "    return var4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NK_RW97'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getModelName()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>interest</th>\n",
       "      <th>inflation</th>\n",
       "      <th>outputgap</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.079687</td>\n",
       "      <td>0.06191</td>\n",
       "      <td>0.38901</td>\n",
       "      <td>1.1702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   interest  inflation  outputgap  output\n",
       "0  0.079687    0.06191    0.38901  1.1702"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unconditionalVariances()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PID Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PID_loss_array = []\n",
    "PID_final_inflation_variance = 0\n",
    "PID_final_output_gap_variance = 0\n",
    "PID_final_interest_rate_variance = 0\n",
    "currentPIDLoss = 0\n",
    "\n",
    "def myPID(selected_coeff, lambdaVal, coeffInterest, modelNum, VarTarget):\n",
    "    global PID_final_inflation_variance\n",
    "    global PID_final_output_gap_variance\n",
    "    global PID_final_interest_rate_variance\n",
    "    global currentPIDLoss\n",
    "\n",
    "    coefficients = [1, 0, 0, 0, \n",
    "                    abs(selected_coeff[0])/4, \n",
    "                    (abs(selected_coeff[0])+selected_coeff[1])/4, \n",
    "                    (abs(selected_coeff[0])+selected_coeff[1])/4, \n",
    "                    (abs(selected_coeff[0])+selected_coeff[1])/4, \n",
    "                    selected_coeff[1]/4, \n",
    "                    0, 0, 0, 0, \n",
    "                    selected_coeff[2], selected_coeff[3], 0, \n",
    "                    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0.25]\n",
    "    scipy.io.savemat('variables.mat', dict(coefficients=coefficients, modelNumber = modelNum)) # Input for MMB.\n",
    "    eng.MMB(nargout = 0) # Run MMB\n",
    "    \n",
    "    variances = unconditionalVariances()\n",
    "    \n",
    "    interest_rate_variance = variances['interest'][0]\n",
    "    inflation_variance = variances['inflation'][0]\n",
    "    output_gap_variance = variances['outputgap'][0]\n",
    "    \n",
    "    PID_final_inflation_variance = inflation_variance\n",
    "    PID_final_output_gap_variance = output_gap_variance\n",
    "    PID_final_interest_rate_variance = interest_rate_variance\n",
    "    \n",
    "    PID_loss = ((interest_rate_variance - VarTarget[0])**2 * coeffInterest \n",
    "                + (inflation_variance / VarTarget[1]) * lambdaVal\n",
    "                + (output_gap_variance/ VarTarget[2]) * (1 - lambdaVal) )\n",
    "    \n",
    "    print(\"myPID Loss\", PID_loss, \"lambda =\", lambdaVal)\n",
    "    PID_loss_array.append(PID_loss)\n",
    "    currentPIDLoss = PID_loss\n",
    "    \n",
    "    return PID_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create frontier function which optimizes myPID as objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFrontier(modelNum):\n",
    "    taylor_coeff = [1.5, 0, 0.5, 0] # Taylor rule coefficients.\n",
    "    hamilton_coeff = [1.42, -1.20, 0.5, -0.48] # Hamilton fit coefficients.\n",
    "    weights = np.arange(0, 1.01, .25) # Values for lambda\n",
    "    interest_coeff = 1.0 # Coefficient on the interest_rate loss term\n",
    "    \n",
    "    # ---\n",
    "    rVarTarget = [16.0, 1.0, 1.0] # # Normalizing coefficients for PID_loss (initial pass)\n",
    "    mylambdatemp = 0.0 # Something to put in the lambda variable when calculating the target rate variance.\n",
    "    # Run with Hamilton coefficients to generate target rate variance.\n",
    "    myfoo = myPID(hamilton_coeff, mylambdatemp, interest_coeff, modelNum, rVarTarget)\n",
    "    VarTarget = [unconditionalVariances()['interest'][0], 1, 1] # Normalizing variances for interest rate\n",
    "    print(\"The target rate variances are\", VarTarget[0]) # Print assigned rate variance.\n",
    "    # ---\n",
    "    \n",
    "    PID_inflation_variances = []\n",
    "    PID_output_gap_variances = []\n",
    "    PID_interest_variances = []\n",
    "    PID_loss_of_lambda = []\n",
    "    PID_coefficients_array = []\n",
    "\n",
    "    # Starting with the Taylor rule coefficients\n",
    "    #current_coeff = taylor_coeff\n",
    "    \n",
    "    # Starting with the Hamilton rule coefficients\n",
    "    current_coeff = hamilton_coeff\n",
    "\n",
    "    for lambda_value in weights:\n",
    "        PID_result = scipy.optimize.minimize(myPID, current_coeff, \\\n",
    "                                    args=(lambda_value, interest_coeff, modelNum, rVarTarget), method='Nelder-Mead')\n",
    "        current_coeff = PID_result.x\n",
    "        PID_coefficients_array.append(current_coeff)\n",
    "        PID_inflation_variances.append(PID_final_inflation_variance)\n",
    "        PID_output_gap_variances.append(PID_final_output_gap_variance)\n",
    "        PID_interest_variances.append(PID_final_interest_rate_variance)\n",
    "        PID_loss_of_lambda.append(currentPIDLoss)\n",
    "    \n",
    "    # The code below plots the frontier\n",
    "    nameOfModel = getModelName()\n",
    "    \n",
    "    SD_inflation_scatter = np.sqrt(np.asarray(PID_inflation_variances))\n",
    "    SD_output_gap_scatter = np.sqrt(np.asarray(PID_output_gap_variances))\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(SD_inflation_scatter, SD_output_gap_scatter, color=\"red\")\n",
    "\n",
    "    for i in range(0, len(weights)):\n",
    "        ax.annotate(weights[i], (SD_inflation_scatter[i], SD_output_gap_scatter[i]))\n",
    "\n",
    "    ax.set_xlabel('$\\sigma_{\\pi}$', fontsize=10)\n",
    "    ax.set_ylabel('$\\sigma_{y}$', fontsize=10)\n",
    "    ax.set_title('Policy Frontiers for Different Weights, Model: ' + nameOfModel, fontsize=14)\n",
    "    saveFileName = nameOfModel + '.pdf'\n",
    "    plt.savefig(saveFileName, bbox_inches='tight')\n",
    "    \n",
    "    # The code below saves the results of the all the optimizations with the appropriate lambdas into a DataFrame\n",
    "    results = dict()\n",
    "    results['lambdas'] = weights\n",
    "    results['inflation_variance'] = PID_inflation_variances\n",
    "    results['output_gap_variance'] = PID_output_gap_variances\n",
    "    results['interest_variance'] = PID_interest_variances\n",
    "    results['loss'] = PID_loss_of_lambda\n",
    "    results['coefficients'] = PID_coefficients_array\n",
    "    results_df = pd.DataFrame.from_dict(results)\n",
    "    \n",
    "    # Saving DataFrame to nameOfModel.csv file\n",
    "    results_df.to_csv(nameOfModel + \".csv\", index=False)\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A normalized version of the createFrontier function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizedCreateFrontier(modelNum):\n",
    "    taylor_coeff = [1.5, 0, 0.5, 0] # Taylor rule coefficients.\n",
    "    hamilton_coeff = [1.42,-1.20,0.5,-0.48] # Hamilton fit coefficients.\n",
    "    weights = np.arange(0, 1.01, .25) # Values for lambda\n",
    "    interest_coeff = 1.0 # Coefficient on the interest_rate loss term (for constrained optimization)\n",
    "    VarTarget = [16.0, 1.0, 1.0] # Normalizing coefficients for PID_loss on inital pass.\n",
    "    \n",
    "    mylambdatemp = 0.0 # Something to put in the lambda variable when calculating the target rate variance.\n",
    "    myfoo = myPID(taylor_coeff, mylambdatemp, interest_coeff, modelNum, VarTarget) # Run with Hamilton coefficients to generate target rate variance.\n",
    "    VarTarget[0] = unconditionalVariances()['interest'][0] # Normalizing variance for interest rate\n",
    "    VarTarget[1] = unconditionalVariances()['inflation'][0] # Normalizing variance for inflation\n",
    "    VarTarget[2] = unconditionalVariances()['outputgap'][0] # Normalizing variance for output gap\n",
    "    print(\"The normalizing variances are\", VarTarget) # Print normalizing variance.\n",
    "    \n",
    "    PID_inflation_variances = []\n",
    "    PID_output_gap_variances = []\n",
    "    PID_interest_variances = []\n",
    "    PID_loss_of_lambda = []\n",
    "    PID_coefficients_array = []\n",
    "    \n",
    "    # Starting with the Taylor rule coefficients\n",
    "    current_coeff = taylor_coeff\n",
    "\n",
    "    for lambda_value in weights:\n",
    "        PID_result = scipy.optimize.minimize(myPID, current_coeff, \\\n",
    "                                    args=(lambda_value, interest_coeff, modelNum, VarTarget), method='Nelder-Mead')\n",
    "        current_coeff = PID_result.x\n",
    "        PID_coefficients_array.append(current_coeff)\n",
    "        PID_inflation_variances.append(PID_final_inflation_variance)\n",
    "        PID_output_gap_variances.append(PID_final_output_gap_variance)\n",
    "        PID_interest_variances.append(PID_final_interest_rate_variance)\n",
    "        PID_loss_of_lambda.append(currentPIDLoss)\n",
    "    \n",
    "    # The code below plots the frontier\n",
    "    nameOfModel = getModelName()\n",
    "    \n",
    "    SD_inflation_scatter = np.asarray([np.sqrt(i) for i in PID_inflation_variances])\n",
    "    SD_output_gap_scatter = np.asarray([np.sqrt(i) for i in PID_output_gap_variances])\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(SD_inflation_scatter, SD_output_gap_scatter, color=\"red\")\n",
    "\n",
    "    for i in range(0, len(weights)):\n",
    "        ax.annotate(weights[i], (SD_inflation_scatter[i], SD_output_gap_scatter[i]))\n",
    "\n",
    "    ax.set_xlabel('$\\sigma_{\\pi}$', fontsize=10)\n",
    "    ax.set_ylabel('$\\sigma_{y}$', fontsize=10)\n",
    "    ax.set_title('Policy Frontiers for Different Weights, Model: ' + nameOfModel, fontsize=14)\n",
    "    saveFileName = nameOfModel + '.pdf'\n",
    "    plt.savefig(saveFileName, bbox_inches='tight')\n",
    "    \n",
    "    # The code below saves the results of the all the optimizations with the appropriate lambdas into a DataFrame\n",
    "    results = dict()\n",
    "    results['lambdas'] = weights\n",
    "    results['inflation_variance'] = PID_inflation_variances\n",
    "    results['output_gap_variance'] = PID_output_gap_variances\n",
    "    results['interest_variance'] = PID_interest_variances\n",
    "    results['loss'] = PID_loss_of_lambda\n",
    "    results['coefficients'] = PID_coefficients_array\n",
    "    results_df = pd.DataFrame.from_dict(results)\n",
    "    \n",
    "    # Saving DataFrame to nameOfModel.csv file\n",
    "    results_df.to_csv(str(modelNum) + \"_\" + nameOfModel + \".csv\", index=False)\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total PID Loss 95.195944 lambda = 0.0\n",
      "The target rate variances are 22.712\n",
      "Total PID Loss 95.195944 lambda = 0.0\n",
      "Total PID Loss 94.11063600000003 lambda = 0.0\n",
      "Total PID Loss 204.34187600000007 lambda = 0.0\n",
      "Total PID Loss 59.523569 lambda = 0.0\n",
      "Total PID Loss 217.61163600000006 lambda = 0.0\n",
      "Total PID Loss 48.96712099999999 lambda = 0.0\n",
      "Total PID Loss 37.605456 lambda = 0.0\n",
      "Total PID Loss 51.322900000000004 lambda = 0.0\n",
      "Total PID Loss 44.77368899999999 lambda = 0.0\n",
      "Total PID Loss 34.554169000000016 lambda = 0.0\n",
      "Total PID Loss 49.307216 lambda = 0.0\n",
      "Total PID Loss 50.12727600000001 lambda = 0.0\n",
      "Total PID Loss 39.98072899999999 lambda = 0.0\n",
      "Total PID Loss 68.71452099999998 lambda = 0.0\n",
      "Total PID Loss 39.029225000000004 lambda = 0.0\n",
      "Total PID Loss 59.40322500000002 lambda = 0.0\n",
      "Total PID Loss 37.381168999999986 lambda = 0.0\n",
      "Total PID Loss 44.092023999999995 lambda = 0.0\n",
      "Total PID Loss 35.516025000000006 lambda = 0.0\n",
      "Total PID Loss 41.11124899999999 lambda = 0.0\n",
      "Total PID Loss 35.71925599999999 lambda = 0.0\n",
      "Total PID Loss 45.56991600000002 lambda = 0.0\n",
      "Total PID Loss 34.71488899999999 lambda = 0.0\n",
      "Total PID Loss 36.69599999999999 lambda = 0.0\n",
      "Total PID Loss 34.77529599999998 lambda = 0.0\n",
      "Total PID Loss 37.97520899999999 lambda = 0.0\n",
      "Total PID Loss 34.700835999999995 lambda = 0.0\n",
      "Total PID Loss 34.1439 lambda = 0.0\n",
      "Total PID Loss 35.04622499999999 lambda = 0.0\n",
      "Total PID Loss 35.15002499999999 lambda = 0.0\n",
      "Total PID Loss 34.28959999999999 lambda = 0.0\n",
      "Total PID Loss 34.900600000000004 lambda = 0.0\n",
      "Total PID Loss 34.290684000000006 lambda = 0.0\n",
      "Total PID Loss 34.59404900000001 lambda = 0.0\n",
      "Total PID Loss 34.23416900000001 lambda = 0.0\n",
      "Total PID Loss 34.65600400000001 lambda = 0.0\n",
      "Total PID Loss 34.23055599999999 lambda = 0.0\n",
      "Total PID Loss 34.07022500000001 lambda = 0.0\n",
      "Total PID Loss 34.177464000000015 lambda = 0.0\n",
      "Total PID Loss 34.10337600000001 lambda = 0.0\n",
      "Total PID Loss 33.881584000000004 lambda = 0.0\n",
      "Total PID Loss 33.819649 lambda = 0.0\n",
      "Total PID Loss 33.989081 lambda = 0.0\n",
      "Total PID Loss 33.693943999999995 lambda = 0.0\n",
      "Total PID Loss 33.657600999999985 lambda = 0.0\n",
      "Total PID Loss 33.529503999999996 lambda = 0.0\n",
      "Total PID Loss 33.539103999999995 lambda = 0.0\n",
      "Total PID Loss 33.448704 lambda = 0.0\n",
      "Total PID Loss 33.595400000000005 lambda = 0.0\n",
      "Total PID Loss 33.776723999999994 lambda = 0.0\n",
      "Total PID Loss 33.32540900000001 lambda = 0.0\n",
      "Total PID Loss 33.48525600000001 lambda = 0.0\n",
      "Total PID Loss 33.449056 lambda = 0.0\n",
      "Total PID Loss 33.125364 lambda = 0.0\n",
      "Total PID Loss 33.17362500000001 lambda = 0.0\n",
      "Total PID Loss 33.04004900000001 lambda = 0.0\n",
      "Total PID Loss 33.122776 lambda = 0.0\n",
      "Total PID Loss 33.02392099999998 lambda = 0.0\n",
      "Total PID Loss 33.254644000000006 lambda = 0.0\n",
      "Total PID Loss 32.74362500000001 lambda = 0.0\n",
      "Total PID Loss 32.75040900000001 lambda = 0.0\n",
      "Total PID Loss 33.187096 lambda = 0.0\n",
      "Total PID Loss 32.94306399999999 lambda = 0.0\n",
      "Total PID Loss 32.554161 lambda = 0.0\n",
      "Total PID Loss 32.32802500000001 lambda = 0.0\n",
      "Total PID Loss 32.792401 lambda = 0.0\n",
      "Total PID Loss 32.246928999999994 lambda = 0.0\n",
      "Total PID Loss 32.03502499999999 lambda = 0.0\n",
      "Total PID Loss 32.782025000000004 lambda = 0.0\n",
      "Total PID Loss 32.45020399999999 lambda = 0.0\n",
      "Total PID Loss 32.70000400000001 lambda = 0.0\n",
      "Total PID Loss 31.882000000000005 lambda = 0.0\n",
      "Total PID Loss 31.737569 lambda = 0.0\n",
      "Total PID Loss 31.919456000000004 lambda = 0.0\n",
      "Total PID Loss 31.383463999999993 lambda = 0.0\n",
      "Total PID Loss 31.194368999999995 lambda = 0.0\n",
      "Total PID Loss 31.046849 lambda = 0.0\n",
      "Total PID Loss 31.208448999999995 lambda = 0.0\n",
      "Total PID Loss 30.594625 lambda = 0.0\n",
      "Total PID Loss 30.180316000000005 lambda = 0.0\n",
      "Total PID Loss 30.833328999999996 lambda = 0.0\n",
      "Total PID Loss 29.574529 lambda = 0.0\n",
      "Total PID Loss 28.980225000000004 lambda = 0.0\n",
      "Total PID Loss 29.774009 lambda = 0.0\n",
      "Total PID Loss 28.718196 lambda = 0.0\n",
      "Total PID Loss 27.76000099999999 lambda = 0.0\n",
      "Total PID Loss 27.269240999999997 lambda = 0.0\n",
      "Total PID Loss 665.4922010000003 lambda = 0.0\n",
      "Total PID Loss 185.961721 lambda = 0.0\n",
      "Total PID Loss 29.081649 lambda = 0.0\n",
      "Total PID Loss 28.548025000000003 lambda = 0.0\n",
      "Total PID Loss 139.46012900000002 lambda = 0.0\n",
      "Total PID Loss 28.371721 lambda = 0.0\n",
      "Total PID Loss 576.373784 lambda = 0.0\n",
      "Total PID Loss 28.36996899999999 lambda = 0.0\n",
      "Total PID Loss 28.857999999999993 lambda = 0.0\n",
      "Total PID Loss 27.956280999999986 lambda = 0.0\n",
      "Total PID Loss 26.92002500000001 lambda = 0.0\n",
      "Total PID Loss 470.31645599999996 lambda = 0.0\n",
      "Total PID Loss 461.2330250000001 lambda = 0.0\n",
      "Total PID Loss 27.85459999999999 lambda = 0.0\n",
      "Total PID Loss 26.581009 lambda = 0.0\n",
      "Total PID Loss 76.8374 lambda = 0.0\n",
      "Total PID Loss 266.374216 lambda = 0.0\n",
      "Total PID Loss 27.372681 lambda = 0.0\n",
      "Total PID Loss 27.286001000000013 lambda = 0.0\n",
      "Total PID Loss 64.671225 lambda = 0.0\n",
      "Total PID Loss 27.028363999999996 lambda = 0.0\n",
      "Total PID Loss 27.402196000000004 lambda = 0.0\n",
      "Total PID Loss 26.91142400000001 lambda = 0.0\n",
      "Total PID Loss 37.160225000000004 lambda = 0.0\n",
      "Total PID Loss 26.943603999999993 lambda = 0.0\n",
      "Total PID Loss 32.26865600000002 lambda = 0.0\n",
      "Total PID Loss 26.858809000000008 lambda = 0.0\n",
      "Total PID Loss 26.852089000000007 lambda = 0.0\n",
      "Total PID Loss 27.028129000000007 lambda = 0.0\n",
      "Total PID Loss 26.654484000000014 lambda = 0.0\n",
      "Total PID Loss 27.733183999999994 lambda = 0.0\n",
      "Total PID Loss 26.711225000000006 lambda = 0.0\n",
      "Total PID Loss 40.462025 lambda = 0.0\n",
      "Total PID Loss 26.719156000000012 lambda = 0.0\n",
      "Total PID Loss 26.849329 lambda = 0.0\n",
      "Total PID Loss 26.732303999999992 lambda = 0.0\n",
      "Total PID Loss 26.55704900000001 lambda = 0.0\n",
      "Total PID Loss 26.852089000000007 lambda = 0.0\n",
      "Total PID Loss 26.460009 lambda = 0.0\n",
      "Total PID Loss 30.53057600000001 lambda = 0.0\n",
      "Total PID Loss 29.778924000000007 lambda = 0.0\n",
      "Total PID Loss 26.612089000000008 lambda = 0.0\n",
      "Total PID Loss 26.530195999999997 lambda = 0.0\n",
      "Total PID Loss 26.442440999999995 lambda = 0.0\n",
      "Total PID Loss 28.527680999999998 lambda = 0.0\n",
      "Total PID Loss 26.799599999999995 lambda = 0.0\n",
      "Total PID Loss 26.52200100000001 lambda = 0.0\n",
      "Total PID Loss 26.530081000000003 lambda = 0.0\n",
      "Total PID Loss 26.644036 lambda = 0.0\n",
      "Total PID Loss 26.492009000000003 lambda = 0.0\n",
      "Total PID Loss 26.55401600000001 lambda = 0.0\n",
      "Total PID Loss 26.478004000000006 lambda = 0.0\n",
      "Total PID Loss 26.51304899999999 lambda = 0.0\n",
      "Total PID Loss 26.422081 lambda = 0.0\n",
      "Total PID Loss 26.841576000000003 lambda = 0.0\n",
      "Total PID Loss 26.466009 lambda = 0.0\n",
      "Total PID Loss 26.430121000000003 lambda = 0.0\n",
      "Total PID Loss 26.776484000000014 lambda = 0.0\n",
      "Total PID Loss 26.442064000000002 lambda = 0.0\n",
      "Total PID Loss 26.447440999999998 lambda = 0.0\n",
      "Total PID Loss 26.432323999999994 lambda = 0.0\n",
      "Total PID Loss 26.421004000000007 lambda = 0.0\n",
      "Total PID Loss 26.439144000000006 lambda = 0.0\n",
      "Total PID Loss 26.46809999999999 lambda = 0.0\n",
      "Total PID Loss 26.42809999999999 lambda = 0.0\n",
      "Total PID Loss 26.443036 lambda = 0.0\n",
      "Total PID Loss 26.423196000000004 lambda = 0.0\n",
      "Total PID Loss 26.445004000000008 lambda = 0.0\n",
      "Total PID Loss 26.420121000000005 lambda = 0.0\n",
      "Total PID Loss 26.409081 lambda = 0.0\n",
      "Total PID Loss 26.397081 lambda = 0.0\n",
      "Total PID Loss 26.411001000000013 lambda = 0.0\n",
      "Total PID Loss 26.429003999999996 lambda = 0.0\n",
      "Total PID Loss 26.413064000000006 lambda = 0.0\n",
      "Total PID Loss 26.413143999999996 lambda = 0.0\n",
      "Total PID Loss 26.415015999999994 lambda = 0.0\n",
      "Total PID Loss 26.397036 lambda = 0.0\n",
      "Total PID Loss 26.413000999999987 lambda = 0.0\n",
      "Total PID Loss 26.399000999999984 lambda = 0.0\n",
      "Total PID Loss 26.525003999999992 lambda = 0.0\n",
      "Total PID Loss 26.403004000000006 lambda = 0.0\n",
      "Total PID Loss 26.452015999999993 lambda = 0.0\n",
      "Total PID Loss 26.402009 lambda = 0.0\n",
      "Total PID Loss 26.455008999999997 lambda = 0.0\n",
      "Total PID Loss 26.402009 lambda = 0.0\n",
      "Total PID Loss 26.408025000000006 lambda = 0.0\n",
      "Total PID Loss 26.39801599999999 lambda = 0.0\n",
      "Total PID Loss 26.432025000000007 lambda = 0.0\n",
      "Total PID Loss 26.39801599999999 lambda = 0.0\n",
      "Total PID Loss 26.405121000000005 lambda = 0.0\n",
      "Total PID Loss 26.394008999999997 lambda = 0.0\n",
      "Total PID Loss 26.39904899999999 lambda = 0.0\n",
      "Total PID Loss 26.396025000000005 lambda = 0.0\n",
      "Total PID Loss 26.403048999999992 lambda = 0.0\n",
      "Total PID Loss 26.396025000000005 lambda = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total PID Loss 26.398 lambda = 0.0\n",
      "Total PID Loss 26.395048999999993 lambda = 0.0\n",
      "Total PID Loss 26.400008999999997 lambda = 0.0\n",
      "Total PID Loss 26.39902500000001 lambda = 0.0\n",
      "Total PID Loss 26.395025000000008 lambda = 0.0\n",
      "Total PID Loss 26.39501599999999 lambda = 0.0\n",
      "Total PID Loss 26.39501599999999 lambda = 0.0\n",
      "Total PID Loss 26.39901599999999 lambda = 0.0\n",
      "Total PID Loss 26.397008999999997 lambda = 0.0\n",
      "Total PID Loss 26.399009 lambda = 0.0\n",
      "Total PID Loss 26.397008999999997 lambda = 0.0\n",
      "Total PID Loss 26.398009000000002 lambda = 0.0\n",
      "Total PID Loss 26.394015999999993 lambda = 0.0\n",
      "Total PID Loss 26.393015999999996 lambda = 0.0\n",
      "Total PID Loss 26.398009000000002 lambda = 0.0\n",
      "Total PID Loss 26.398009000000002 lambda = 0.0\n",
      "Total PID Loss 26.397008999999997 lambda = 0.0\n",
      "Total PID Loss 26.394015999999993 lambda = 0.0\n",
      "Total PID Loss 26.398009000000002 lambda = 0.0\n",
      "Total PID Loss 26.398009000000002 lambda = 0.0\n",
      "Total PID Loss 26.399009 lambda = 0.0\n",
      "Total PID Loss 26.399009 lambda = 0.0\n",
      "Total PID Loss 26.394015999999993 lambda = 0.0\n",
      "Total PID Loss 26.398009000000002 lambda = 0.0\n",
      "Total PID Loss 26.399009 lambda = 0.0\n",
      "Total PID Loss 26.399009 lambda = 0.0\n",
      "Total PID Loss 26.399009 lambda = 0.0\n",
      "Total PID Loss 26.399009 lambda = 0.0\n",
      "Total PID Loss 26.393015999999996 lambda = 0.0\n",
      "Total PID Loss 26.399009 lambda = 0.0\n",
      "Total PID Loss 26.399009 lambda = 0.0\n",
      "Total PID Loss 26.399009 lambda = 0.0\n",
      "Total PID Loss 26.399009 lambda = 0.0\n",
      "Total PID Loss 26.399009 lambda = 0.0\n",
      "Total PID Loss 26.393015999999996 lambda = 0.0\n",
      "Total PID Loss 26.399009 lambda = 0.0\n"
     ]
    }
   ],
   "source": [
    "# Model Number 15 - US FRB03\n",
    "m15results = createFrontier(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m15resultsnorm = normalizedCreateFrontier(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section: Optimization across models/regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "PID_loss_array = []\n",
    "PID_final_inflation_variance = 0\n",
    "PID_final_output_gap_variance = 0\n",
    "PID_final_interest_rate_variance = 0\n",
    "currentPIDLoss = 0\n",
    "\n",
    "# Without normalization\n",
    "def multiplePID(selected_coeff, lambdaVal, coeffInterest, modelNums, normalizing_matrix):\n",
    "    global PID_final_inflation_variance\n",
    "    global PID_final_output_gap_variance\n",
    "    global PID_final_interest_rate_variance\n",
    "    global currentPIDLoss\n",
    "\n",
    "    coefficients = [1, 0, 0, 0, \n",
    "                    abs(selected_coeff[0])/4, \n",
    "                    (abs(selected_coeff[0])+selected_coeff[1])/4, \n",
    "                    (abs(selected_coeff[0])+selected_coeff[1])/4, \n",
    "                    (abs(selected_coeff[0])+selected_coeff[1])/4, \n",
    "                    selected_coeff[1]/4, \n",
    "                    0, 0, 0, 0, \n",
    "                    selected_coeff[2], selected_coeff[3], 0, \n",
    "                    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0.25]\n",
    "    \n",
    "    # Initializing the PID loss to 0\n",
    "    n = len(modelNums)\n",
    "    weight = 1.0/n\n",
    "    sumOfInterestVariances = 0\n",
    "    sumOfInflationVariances = 0\n",
    "    sumOfOutputGapVariances = 0\n",
    "    \n",
    "    # Running each model in modelNums\n",
    "    for i in range(n):\n",
    "        scipy.io.savemat('variables.mat', dict(coefficients=coefficients, modelNumber = modelNums[i])) # Input for MMB.\n",
    "        eng.MMB(nargout = 0) # Run MMB\n",
    "        variances = unconditionalVariances()\n",
    "        \n",
    "        # Inverse weight each of these by Taylor variances to `normalize`\n",
    "        interest_rate_variance = ((variances['interest'][0] - normalizing_matrix[i][0])/normalizing_matrix[i][0])**2\n",
    "        inflation_variance = variances['inflation'][0]/normalizing_matrix[i][1]\n",
    "        output_gap_variance = variances['outputgap'][0]/normalizing_matrix[i][2]\n",
    "        \n",
    "        sumOfInterestVariances += interest_rate_variance\n",
    "        sumOfInflationVariances += inflation_variance\n",
    "        sumOfOutputGapVariances += output_gap_variance\n",
    "    \n",
    "    PID_final_inflation_variance = 1.0/n * sumOfInflationVariances\n",
    "    PID_final_output_gap_variance = 1.0/n * sumOfOutputGapVariances\n",
    "    PID_final_interest_rate_variance = 1.0/n * sumOfInterestVariances\n",
    "    \n",
    "    PID_loss = ((PID_final_interest_rate_variance) * coeffInterest \n",
    "                + (PID_final_inflation_variance) * lambdaVal\n",
    "                + (PID_final_output_gap_variance) * (1 - lambdaVal))\n",
    "    \n",
    "    print(\"Current PID Loss\", PID_loss, \"lambda =\", lambdaVal)\n",
    "    PID_loss_array.append(PID_loss)\n",
    "    currentPIDLoss = PID_loss\n",
    "    \n",
    "    return PID_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createGroupedFrontier(modelNums):\n",
    "    taylor_coeff = [1.5, 0, 0.5, 0] # Taylor rule coefficients.\n",
    "    hamilton_coeff = [1.42,-1.20,0.5,-0.48] # Hamilton fit coefficients.\n",
    "    weights = np.arange(0, 1.01, .25) # Values for lambda\n",
    "    interest_coeff = 1.0 # Coefficient on the interest_rate loss term (for constrained optimization)\n",
    "    VarTarget = [16.0, 1.0, 1.0] # Normalizing coefficients for PID_loss on inital pass.\n",
    "    \n",
    "    normalizing_matrix = []\n",
    "    mylambdatemp = 0.0 # Something to put in the lambda variable when calculating the target rate variance.\n",
    "    \n",
    "    for modelNum in modelNums:\n",
    "        # Run with Taylor coefficients to generate target rate variance.\n",
    "        myfoo = myPID(taylor_coeff, mylambdatemp, interest_coeff, modelNum, VarTarget)\n",
    "        interest_m = unconditionalVariances()['interest'][0] # Normalizing variance for interest rate\n",
    "        inflation_m = unconditionalVariances()['inflation'][0] # Normalizing variance for inflation\n",
    "        output_gap_m = unconditionalVariances()['outputgap'][0] # Normalizing variance for output gap\n",
    "        normalizing_matrix.append([interest_m, inflation_m, output_gap_m])\n",
    "    \n",
    "    PID_inflation_variances = []\n",
    "    PID_output_gap_variances = []\n",
    "    PID_interest_variances = []\n",
    "    PID_loss_of_lambda = []\n",
    "    PID_coefficients_array = []\n",
    "    \n",
    "    # Starting with the Taylor rule coefficients\n",
    "    current_coeff = taylor_coeff\n",
    "\n",
    "    for lambda_value in weights:\n",
    "        PID_result = scipy.optimize.minimize(multiplePID, current_coeff, \\\n",
    "                                    args=(lambda_value, interest_coeff, modelNums, normalizing_matrix), method='Nelder-Mead')\n",
    "        current_coeff = PID_result.x\n",
    "        \n",
    "        # Appending to the results\n",
    "        PID_coefficients_array.append(current_coeff)\n",
    "        PID_inflation_variances.append(PID_final_inflation_variance)\n",
    "        PID_output_gap_variances.append(PID_final_output_gap_variance)\n",
    "        PID_interest_variances.append(PID_final_interest_rate_variance)\n",
    "        PID_loss_of_lambda.append(currentPIDLoss)\n",
    "    \n",
    "    # The code below plots the frontier\n",
    "    modelNumbers = '_'.join(str(x) for x in modelNums)\n",
    "    \n",
    "    SD_inflation_scatter = np.asarray([np.sqrt(i) for i in PID_inflation_variances])\n",
    "    SD_output_gap_scatter = np.asarray([np.sqrt(i) for i in PID_output_gap_variances])\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(SD_inflation_scatter, SD_output_gap_scatter, color=\"red\")\n",
    "\n",
    "    for i in range(0, len(weights)):\n",
    "        ax.annotate(weights[i], (SD_inflation_scatter[i], SD_output_gap_scatter[i]))\n",
    "\n",
    "    ax.set_xlabel('$\\sigma_{\\pi}$', fontsize=10)\n",
    "    ax.set_ylabel('$\\sigma_{y}$', fontsize=10)\n",
    "    ax.set_title('Policy Frontiers for Different Weights, Multiple Models: ' + modelNumbers, fontsize=14)\n",
    "    saveFileName = \"Multiple_\" + modelNumbers + '.pdf'\n",
    "    plt.savefig(saveFileName, bbox_inches='tight')\n",
    "    \n",
    "    # The code below saves the results of the all the optimizations with the appropriate lambdas into a DataFrame\n",
    "    results = dict()\n",
    "    results['lambdas'] = weights\n",
    "    results['inflation_variance'] = PID_inflation_variances\n",
    "    results['output_gap_variance'] = PID_output_gap_variances\n",
    "    results['interest_variance'] = PID_interest_variances\n",
    "    results['loss'] = PID_loss_of_lambda\n",
    "    results['pi_t'] = [array[0] for array in PID_coefficients_array]\n",
    "    results['pi_t-1'] = [array[1] for array in PID_coefficients_array]\n",
    "    results['y_t'] = [array[2] for array in PID_coefficients_array]\n",
    "    results['y_t-1'] = [array[3] for array in PID_coefficients_array]\n",
    "    results_df = pd.DataFrame.from_dict(results)\n",
    "    \n",
    "    # Saving DataFrame to nameOfModel.csv file\n",
    "    results_df.to_csv(\"Multiple_\" + modelNumbers + \".csv\", index=False)\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generates a multiple model (grouped Frontier) for models 107, 108\n",
    "To run the model please call `createGroupedFrontier` with a `list` of the required model numbers:\n",
    "\n",
    "For example: `createGroupedFrontier([107, 108])`\n",
    "\n",
    "After the optimization has completed, your folder (wherever this notebook Structured_Frontier is saved) should contain a pdf image eg. `Multiple_107_108.pdf` and a .csv file `Multiple_107_108.csv` with the results of the optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myPID Loss 36770968.01 lambda = 0.0\n",
      "myPID Loss 29729117.639999997 lambda = 0.0\n",
      "Current PID Loss 1.0 lambda = 0.0\n",
      "Current PID Loss 1.0137334293238116 lambda = 0.0\n",
      "Current PID Loss 1.000014222474835 lambda = 0.0\n",
      "Current PID Loss 0.9981391275275352 lambda = 0.0\n",
      "Current PID Loss 0.9999337486780276 lambda = 0.0\n",
      "Current PID Loss 1.001977519451962 lambda = 0.0\n",
      "Current PID Loss 0.9971798333757138 lambda = 0.0\n",
      "Current PID Loss 0.9976841965963403 lambda = 0.0\n",
      "Current PID Loss 1.001237936033166 lambda = 0.0\n",
      "Current PID Loss 0.9977401989538215 lambda = 0.0\n",
      "Current PID Loss 1.0032449495716622 lambda = 0.0\n",
      "Current PID Loss 0.9975595679503603 lambda = 0.0\n",
      "Current PID Loss 0.99770507379051 lambda = 0.0\n",
      "Current PID Loss 0.9972264381725131 lambda = 0.0\n",
      "Current PID Loss 0.9998658611050272 lambda = 0.0\n",
      "Current PID Loss 0.9969620431892837 lambda = 0.0\n",
      "Current PID Loss 0.9971355976978025 lambda = 0.0\n",
      "Current PID Loss 0.9971508244620254 lambda = 0.0\n",
      "Current PID Loss 0.9968561510394288 lambda = 0.0\n",
      "Current PID Loss 0.9975824809353669 lambda = 0.0\n",
      "Current PID Loss 0.9973065098603695 lambda = 0.0\n",
      "Current PID Loss 0.9967987851491305 lambda = 0.0\n",
      "Current PID Loss 0.9989288956907966 lambda = 0.0\n",
      "Current PID Loss 0.9966636405867954 lambda = 0.0\n",
      "Current PID Loss 0.9969873416841385 lambda = 0.0\n",
      "Current PID Loss 0.9967813444469172 lambda = 0.0\n",
      "Current PID Loss 0.9967125919279896 lambda = 0.0\n",
      "Current PID Loss 0.9977069720156975 lambda = 0.0\n",
      "Current PID Loss 0.996657512367131 lambda = 0.0\n",
      "Current PID Loss 0.9965238751314358 lambda = 0.0\n",
      "Current PID Loss 0.9963811777725815 lambda = 0.0\n",
      "Current PID Loss 0.9963735242348778 lambda = 0.0\n",
      "Current PID Loss 0.9961648511782524 lambda = 0.0\n",
      "Current PID Loss 0.9963904681917871 lambda = 0.0\n",
      "Current PID Loss 0.9961803051222344 lambda = 0.0\n",
      "Current PID Loss 0.9958266550884168 lambda = 0.0\n",
      "Current PID Loss 0.9954136041136641 lambda = 0.0\n",
      "Current PID Loss 0.9957631477309047 lambda = 0.0\n",
      "Current PID Loss 0.9952934967836577 lambda = 0.0\n",
      "Current PID Loss 0.9947166668354601 lambda = 0.0\n",
      "Current PID Loss 0.995125526263429 lambda = 0.0\n",
      "Current PID Loss 0.994202621043862 lambda = 0.0\n",
      "Current PID Loss 0.9931261036035274 lambda = 0.0\n",
      "Current PID Loss 0.9932441215248664 lambda = 0.0\n",
      "Current PID Loss 0.9925161371095741 lambda = 0.0\n",
      "Current PID Loss 0.9909091562522633 lambda = 0.0\n",
      "Current PID Loss 0.9906445403602668 lambda = 0.0\n",
      "Current PID Loss 0.9880465511606362 lambda = 0.0\n",
      "Current PID Loss 0.9873897894833664 lambda = 0.0\n",
      "Current PID Loss 0.983416220749139 lambda = 0.0\n",
      "Current PID Loss 0.9832568059378581 lambda = 0.0\n",
      "Current PID Loss 0.9777597259021722 lambda = 0.0\n",
      "Current PID Loss 0.9711964290432694 lambda = 0.0\n",
      "Current PID Loss 1.8290436257740312 lambda = 0.0\n",
      "Current PID Loss 0.9664473962208231 lambda = 0.0\n",
      "Current PID Loss 3.629639447023088 lambda = 0.0\n",
      "Current PID Loss 102.61042402046087 lambda = 0.0\n",
      "Current PID Loss 0.9807678288417007 lambda = 0.0\n",
      "Current PID Loss 0.9540012360978761 lambda = 0.0\n",
      "Current PID Loss 1.476030119112743 lambda = 0.0\n",
      "Current PID Loss 9.356737030942881 lambda = 0.0\n",
      "Current PID Loss 0.9736502645799165 lambda = 0.0\n",
      "Current PID Loss 0.9439293395345424 lambda = 0.0\n",
      "Current PID Loss 0.936412749474667 lambda = 0.0\n",
      "Current PID Loss 1.2887713408096744 lambda = 0.0\n",
      "Current PID Loss 0.9644456963316569 lambda = 0.0\n",
      "Current PID Loss 1.016866693756087 lambda = 0.0\n",
      "Current PID Loss 0.9624170987244651 lambda = 0.0\n",
      "Current PID Loss 0.9453040571325793 lambda = 0.0\n",
      "Current PID Loss 0.9467693189744267 lambda = 0.0\n",
      "Current PID Loss 1.4600225077779025 lambda = 0.0\n",
      "Current PID Loss 0.949480486657173 lambda = 0.0\n",
      "Current PID Loss 0.8943422383695961 lambda = 0.0\n",
      "Current PID Loss 1.1020706212322824 lambda = 0.0\n",
      "Current PID Loss 1.2529093838569494 lambda = 0.0\n",
      "Current PID Loss 0.9347001237250969 lambda = 0.0\n",
      "Current PID Loss 0.9363930932291908 lambda = 0.0\n",
      "Current PID Loss 1.377214661714587 lambda = 0.0\n",
      "Current PID Loss 0.9329903704726724 lambda = 0.0\n",
      "Current PID Loss 0.9460613897740455 lambda = 0.0\n",
      "Current PID Loss 0.9157554196094254 lambda = 0.0\n",
      "Current PID Loss 0.9477423077931 lambda = 0.0\n",
      "Current PID Loss 0.9281501119658639 lambda = 0.0\n",
      "Current PID Loss 0.9003407298026562 lambda = 0.0\n",
      "Current PID Loss 0.8935455943740092 lambda = 0.0\n",
      "Current PID Loss 1.8117147374832685 lambda = 0.0\n",
      "Current PID Loss 1.8163820763649678 lambda = 0.0\n",
      "Current PID Loss 0.9135350701679478 lambda = 0.0\n",
      "Current PID Loss 0.8802841617993464 lambda = 0.0\n",
      "Current PID Loss 0.8807465219419048 lambda = 0.0\n",
      "Current PID Loss 0.9161323033847264 lambda = 0.0\n",
      "Current PID Loss 0.9008208145146422 lambda = 0.0\n",
      "Current PID Loss 0.8784068524347871 lambda = 0.0\n",
      "Current PID Loss 0.9161323033847264 lambda = 0.0\n",
      "Current PID Loss 1.0442520650153022 lambda = 0.0\n",
      "Current PID Loss 0.8899427578329108 lambda = 0.0\n",
      "Current PID Loss 0.8736474373006968 lambda = 0.0\n"
     ]
    }
   ],
   "source": [
    "m_107_108_results = createGroupedFrontier([107, 108]) # Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
